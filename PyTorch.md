[PyTorch](https://pytorch.org/) is an optimized tensor library for deep learning using GPUs and CPUs. It based on [Torch](https://github.com/torch/torch7) library for applications such as computer vision and natural language processing,[6] primarily developed by Facebook's AI Research lab (FAIR).

A number of pieces of deep learning software are built on top of PyTorch, including Tesla Autopilot, Uber's Pyro, HuggingFace's Transformers, PyTorch Lightning, and Catalyst.

PyTorch provides two high-level features:

- Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU)
- Deep neural networks built on a type-based automatic differentiation system

PyTorch defines a class called Tensor (torch.Tensor) to store and operate on homogeneous multidimensional rectangular arrays of numbers. PyTorch Tensors are similar to NumPy Arrays, but can also be operated on a CUDA-capable Nvidia GPU. PyTorch supports various sub-types of Tensors.


## PyTorch vs TensorFlow

[TensorFlow](Tensorflow) is developed by Google Brain and actively used at Google both for research and production needs. Its closed-source predecessor is called DistBelief.

PyTorch is a cousin of lua-based Torch framework which was developed and used at Facebook. However, PyTorch is not a simple set of wrappers to support popular language, it was rewritten and tailored to be fast and feel native.


https://towardsdatascience.com/pytorch-vs-tensorflow-spotting-the-difference-25c75777377b





